# **Harmonizing gaze and nature: Integrating plant signals and eye tracking data for a music transcoding compositional process**

# ğŸ‘ï¸ğŸ¼ **From Gaze, Image & Plant Data to Music** ğŸŒ±ğŸ¶  

## **ğŸ”¬ Data-driven musical composition: Analyzing eye movements, images & nature**  

This notebook explores how **gaze tracking, image processing, and plant data** can be transformed into **musical elements** through structured analysis. The goal is to create a **data-driven composition** that reflects visual attention patterns and natural elements in music.  

### **âœ¨ What does this notebook do?**  
- **Processes gaze-tracking data** to analyze visual focus points  
- **Extracts features from images** to influence musical parameters  
- **Analyzes plant growth and environmental data** for musical inspiration  
- **Maps numerical values to musical elements** (pitch, rhythm, dynamics)  
- **Generates and exports music compositions** in **MusicXML and MIDI**  
- **Visualizes gaze patterns, image textures, and plant metrics**  

ğŸ¶ ## ğŸš€ Open the Notebook in Google Colab  
Click the button below to open and run this notebook in Google Colab:  

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RominaSR/gaze-image-and-plant-data-analysis-to-music/blob/main/Gaze_image_plant_data_analysis.ipynb)


